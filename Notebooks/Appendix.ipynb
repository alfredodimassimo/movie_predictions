{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a7f083b7",
   "metadata": {},
   "source": [
    "# Appendix\n",
    "\n",
    "#### Alfredo Di Massimo\n",
    "\n",
    "#### BrainStation, Data Science\n",
    "\n",
    "#### April 4th, 2022"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2f5c674",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aaa07ca",
   "metadata": {},
   "source": [
    "This notebook will be used to perform tasks required within other notebooks, but will minimize on the actual copmutations performed within our analysis. The primary tasks being completed are:\n",
    "- Importing the reviews\n",
    "- Creating a custom stopwords list for NLP analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09fe8024",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os, glob\n",
    "from sklearn.feature_extraction import text\n",
    "import nltk\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c74888cf",
   "metadata": {},
   "source": [
    "## Reviews Import"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75501ef6",
   "metadata": {},
   "source": [
    "The reviews collected from the [IMDb Sentiment Analysis](https://paperswithcode.com/dataset/imdb-movie-reviews) study conducted by Andrew L. Maas et al. divides the reviews into already-separated train and test files for machine learning further separated by positive and negative sentiment. Given the sheer size of each review file, this notebook will solely serve to import the individual 50,000 review text files and save them to `.csv` so as to be able to access the information in a much more computationally efficient way for data processing and exploration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6df497ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "### WARNING: 1 HOUR CELL\n",
    "# Specify directory and create a list with all file names\n",
    "\n",
    "#TEST POSITIVE\n",
    "os.chdir(r\"C:\\Users\\Alfredo\\OneDrive\\Desktop\\Alfredo's File\\Brainstation\\Winter 2022 Data Science Bootcamp\\Projects\\Capstone\\Data\\Reviews\\test\\pos\")\n",
    "filenames_test_pos = [i for i in glob.glob(f\"*.txt\")]\n",
    "df_test_pos = pd.concat([pd.read_table(item, names=[item]) for item in filenames_test_pos]) #Create dataframe to store reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "acc2d55d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0_10.txt</th>\n",
       "      <th>10000_7.txt</th>\n",
       "      <th>10001_9.txt</th>\n",
       "      <th>10002_8.txt</th>\n",
       "      <th>10003_8.txt</th>\n",
       "      <th>10004_9.txt</th>\n",
       "      <th>10005_8.txt</th>\n",
       "      <th>10006_7.txt</th>\n",
       "      <th>10007_10.txt</th>\n",
       "      <th>10008_8.txt</th>\n",
       "      <th>...</th>\n",
       "      <th>9993_10.txt</th>\n",
       "      <th>9994_10.txt</th>\n",
       "      <th>9995_8.txt</th>\n",
       "      <th>9996_10.txt</th>\n",
       "      <th>9997_10.txt</th>\n",
       "      <th>9998_8.txt</th>\n",
       "      <th>9999_10.txt</th>\n",
       "      <th>999_8.txt</th>\n",
       "      <th>99_10.txt</th>\n",
       "      <th>9_7.txt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I went and saw this movie last night after bei...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Actor turned director Bill Paxton follows up h...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>As a recreational golfer with some knowledge o...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I saw this film in a sneak preview, and it is ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bill Paxton has taken the true story of the 19...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 12500 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            0_10.txt  \\\n",
       "0  I went and saw this movie last night after bei...   \n",
       "0                                                NaN   \n",
       "0                                                NaN   \n",
       "0                                                NaN   \n",
       "0                                                NaN   \n",
       "\n",
       "                                         10000_7.txt  \\\n",
       "0                                                NaN   \n",
       "0  Actor turned director Bill Paxton follows up h...   \n",
       "0                                                NaN   \n",
       "0                                                NaN   \n",
       "0                                                NaN   \n",
       "\n",
       "                                         10001_9.txt  \\\n",
       "0                                                NaN   \n",
       "0                                                NaN   \n",
       "0  As a recreational golfer with some knowledge o...   \n",
       "0                                                NaN   \n",
       "0                                                NaN   \n",
       "\n",
       "                                         10002_8.txt  \\\n",
       "0                                                NaN   \n",
       "0                                                NaN   \n",
       "0                                                NaN   \n",
       "0  I saw this film in a sneak preview, and it is ...   \n",
       "0                                                NaN   \n",
       "\n",
       "                                         10003_8.txt 10004_9.txt 10005_8.txt  \\\n",
       "0                                                NaN         NaN         NaN   \n",
       "0                                                NaN         NaN         NaN   \n",
       "0                                                NaN         NaN         NaN   \n",
       "0                                                NaN         NaN         NaN   \n",
       "0  Bill Paxton has taken the true story of the 19...         NaN         NaN   \n",
       "\n",
       "  10006_7.txt 10007_10.txt 10008_8.txt  ... 9993_10.txt 9994_10.txt  \\\n",
       "0         NaN          NaN         NaN  ...         NaN         NaN   \n",
       "0         NaN          NaN         NaN  ...         NaN         NaN   \n",
       "0         NaN          NaN         NaN  ...         NaN         NaN   \n",
       "0         NaN          NaN         NaN  ...         NaN         NaN   \n",
       "0         NaN          NaN         NaN  ...         NaN         NaN   \n",
       "\n",
       "  9995_8.txt 9996_10.txt 9997_10.txt 9998_8.txt 9999_10.txt 999_8.txt  \\\n",
       "0        NaN         NaN         NaN        NaN         NaN       NaN   \n",
       "0        NaN         NaN         NaN        NaN         NaN       NaN   \n",
       "0        NaN         NaN         NaN        NaN         NaN       NaN   \n",
       "0        NaN         NaN         NaN        NaN         NaN       NaN   \n",
       "0        NaN         NaN         NaN        NaN         NaN       NaN   \n",
       "\n",
       "  99_10.txt 9_7.txt  \n",
       "0       NaN     NaN  \n",
       "0       NaN     NaN  \n",
       "0       NaN     NaN  \n",
       "0       NaN     NaN  \n",
       "0       NaN     NaN  \n",
       "\n",
       "[5 rows x 12500 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_pos.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "01062e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_pos.to_csv('df_test_pos.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e17d299b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### WARNING: 1 HOUR CELL\n",
    "##TEST NEGATIVE\n",
    "os.chdir(r\"C:\\Users\\Alfredo\\OneDrive\\Desktop\\Alfredo's File\\Brainstation\\Winter 2022 Data Science Bootcamp\\Projects\\Capstone\\Data\\Reviews\\test\\neg\")\n",
    "filenames_test_neg = [i for i in glob.glob(f\"*.txt\")]\n",
    "df_test_neg = pd.concat([pd.read_table(item, names=[item]) for item in filenames_test_neg])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5205b816",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0_2.txt</th>\n",
       "      <th>10000_4.txt</th>\n",
       "      <th>10001_1.txt</th>\n",
       "      <th>10002_3.txt</th>\n",
       "      <th>10003_3.txt</th>\n",
       "      <th>10004_2.txt</th>\n",
       "      <th>10005_2.txt</th>\n",
       "      <th>10006_2.txt</th>\n",
       "      <th>10007_4.txt</th>\n",
       "      <th>10008_4.txt</th>\n",
       "      <th>...</th>\n",
       "      <th>9993_2.txt</th>\n",
       "      <th>9994_3.txt</th>\n",
       "      <th>9995_2.txt</th>\n",
       "      <th>9996_2.txt</th>\n",
       "      <th>9997_2.txt</th>\n",
       "      <th>9998_1.txt</th>\n",
       "      <th>9999_1.txt</th>\n",
       "      <th>999_3.txt</th>\n",
       "      <th>99_3.txt</th>\n",
       "      <th>9_4.txt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Once again Mr. Costner has dragged out a movie...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>This is an example of why the majority of acti...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>First of all I hate those moronic rappers, who...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Not even the Beatles could write songs everyon...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Brass pictures (movies is not a fitting word f...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 12500 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             0_2.txt  \\\n",
       "0  Once again Mr. Costner has dragged out a movie...   \n",
       "0                                                NaN   \n",
       "0                                                NaN   \n",
       "0                                                NaN   \n",
       "0                                                NaN   \n",
       "\n",
       "                                         10000_4.txt  \\\n",
       "0                                                NaN   \n",
       "0  This is an example of why the majority of acti...   \n",
       "0                                                NaN   \n",
       "0                                                NaN   \n",
       "0                                                NaN   \n",
       "\n",
       "                                         10001_1.txt  \\\n",
       "0                                                NaN   \n",
       "0                                                NaN   \n",
       "0  First of all I hate those moronic rappers, who...   \n",
       "0                                                NaN   \n",
       "0                                                NaN   \n",
       "\n",
       "                                         10002_3.txt  \\\n",
       "0                                                NaN   \n",
       "0                                                NaN   \n",
       "0                                                NaN   \n",
       "0  Not even the Beatles could write songs everyon...   \n",
       "0                                                NaN   \n",
       "\n",
       "                                         10003_3.txt 10004_2.txt 10005_2.txt  \\\n",
       "0                                                NaN         NaN         NaN   \n",
       "0                                                NaN         NaN         NaN   \n",
       "0                                                NaN         NaN         NaN   \n",
       "0                                                NaN         NaN         NaN   \n",
       "0  Brass pictures (movies is not a fitting word f...         NaN         NaN   \n",
       "\n",
       "  10006_2.txt 10007_4.txt 10008_4.txt  ... 9993_2.txt 9994_3.txt 9995_2.txt  \\\n",
       "0         NaN         NaN         NaN  ...        NaN        NaN        NaN   \n",
       "0         NaN         NaN         NaN  ...        NaN        NaN        NaN   \n",
       "0         NaN         NaN         NaN  ...        NaN        NaN        NaN   \n",
       "0         NaN         NaN         NaN  ...        NaN        NaN        NaN   \n",
       "0         NaN         NaN         NaN  ...        NaN        NaN        NaN   \n",
       "\n",
       "  9996_2.txt 9997_2.txt 9998_1.txt 9999_1.txt 999_3.txt 99_3.txt 9_4.txt  \n",
       "0        NaN        NaN        NaN        NaN       NaN      NaN     NaN  \n",
       "0        NaN        NaN        NaN        NaN       NaN      NaN     NaN  \n",
       "0        NaN        NaN        NaN        NaN       NaN      NaN     NaN  \n",
       "0        NaN        NaN        NaN        NaN       NaN      NaN     NaN  \n",
       "0        NaN        NaN        NaN        NaN       NaN      NaN     NaN  \n",
       "\n",
       "[5 rows x 12500 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_neg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "89a04da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_neg.to_csv('df_test_neg.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3b2b0146",
   "metadata": {},
   "outputs": [],
   "source": [
    "### WARNING: 1 HOUR CELL\n",
    "#TRAIN POSITIVE\n",
    "os.chdir(r\"C:\\Users\\Alfredo\\OneDrive\\Desktop\\Alfredo's File\\Brainstation\\Winter 2022 Data Science Bootcamp\\Projects\\Capstone\\Data\\Reviews\\train\\pos\")\n",
    "filenames_train_pos = [i for i in glob.glob(f\"*.txt\")]\n",
    "df_train_pos = pd.concat([pd.read_table(item, names=[item]) for item in filenames_train_pos])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "19fa3a14",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0_9.txt</th>\n",
       "      <th>10000_8.txt</th>\n",
       "      <th>10001_10.txt</th>\n",
       "      <th>10002_7.txt</th>\n",
       "      <th>10003_8.txt</th>\n",
       "      <th>10004_8.txt</th>\n",
       "      <th>10005_7.txt</th>\n",
       "      <th>10006_7.txt</th>\n",
       "      <th>10007_7.txt</th>\n",
       "      <th>10008_7.txt</th>\n",
       "      <th>...</th>\n",
       "      <th>9993_10.txt</th>\n",
       "      <th>9994_10.txt</th>\n",
       "      <th>9995_10.txt</th>\n",
       "      <th>9996_9.txt</th>\n",
       "      <th>9997_7.txt</th>\n",
       "      <th>9998_9.txt</th>\n",
       "      <th>9999_8.txt</th>\n",
       "      <th>999_10.txt</th>\n",
       "      <th>99_8.txt</th>\n",
       "      <th>9_7.txt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bromwell High is a cartoon comedy. It ran at t...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Homelessness (or Houselessness as George Carli...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Brilliant over-acting by Lesley Ann Warren. Be...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>This is easily the most underrated film inn th...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>This is not the typical Mel Brooks film. It wa...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 12500 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             0_9.txt  \\\n",
       "0  Bromwell High is a cartoon comedy. It ran at t...   \n",
       "0                                                NaN   \n",
       "0                                                NaN   \n",
       "0                                                NaN   \n",
       "0                                                NaN   \n",
       "\n",
       "                                         10000_8.txt  \\\n",
       "0                                                NaN   \n",
       "0  Homelessness (or Houselessness as George Carli...   \n",
       "0                                                NaN   \n",
       "0                                                NaN   \n",
       "0                                                NaN   \n",
       "\n",
       "                                        10001_10.txt  \\\n",
       "0                                                NaN   \n",
       "0                                                NaN   \n",
       "0  Brilliant over-acting by Lesley Ann Warren. Be...   \n",
       "0                                                NaN   \n",
       "0                                                NaN   \n",
       "\n",
       "                                         10002_7.txt  \\\n",
       "0                                                NaN   \n",
       "0                                                NaN   \n",
       "0                                                NaN   \n",
       "0  This is easily the most underrated film inn th...   \n",
       "0                                                NaN   \n",
       "\n",
       "                                         10003_8.txt 10004_8.txt 10005_7.txt  \\\n",
       "0                                                NaN         NaN         NaN   \n",
       "0                                                NaN         NaN         NaN   \n",
       "0                                                NaN         NaN         NaN   \n",
       "0                                                NaN         NaN         NaN   \n",
       "0  This is not the typical Mel Brooks film. It wa...         NaN         NaN   \n",
       "\n",
       "  10006_7.txt 10007_7.txt 10008_7.txt  ... 9993_10.txt 9994_10.txt  \\\n",
       "0         NaN         NaN         NaN  ...         NaN         NaN   \n",
       "0         NaN         NaN         NaN  ...         NaN         NaN   \n",
       "0         NaN         NaN         NaN  ...         NaN         NaN   \n",
       "0         NaN         NaN         NaN  ...         NaN         NaN   \n",
       "0         NaN         NaN         NaN  ...         NaN         NaN   \n",
       "\n",
       "  9995_10.txt 9996_9.txt 9997_7.txt 9998_9.txt 9999_8.txt 999_10.txt 99_8.txt  \\\n",
       "0         NaN        NaN        NaN        NaN        NaN        NaN      NaN   \n",
       "0         NaN        NaN        NaN        NaN        NaN        NaN      NaN   \n",
       "0         NaN        NaN        NaN        NaN        NaN        NaN      NaN   \n",
       "0         NaN        NaN        NaN        NaN        NaN        NaN      NaN   \n",
       "0         NaN        NaN        NaN        NaN        NaN        NaN      NaN   \n",
       "\n",
       "  9_7.txt  \n",
       "0     NaN  \n",
       "0     NaN  \n",
       "0     NaN  \n",
       "0     NaN  \n",
       "0     NaN  \n",
       "\n",
       "[5 rows x 12500 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_pos.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "19cda0b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_pos.to_csv('df_train_pos.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fe061636",
   "metadata": {},
   "outputs": [],
   "source": [
    "### WARNING: 1 HOUR CELL\n",
    "#TRAIN NEGATIVE\n",
    "os.chdir(r\"C:\\Users\\Alfredo\\OneDrive\\Desktop\\Alfredo's File\\Brainstation\\Winter 2022 Data Science Bootcamp\\Projects\\Capstone\\Data\\Reviews\\train\\neg\")\n",
    "filenames_train_neg = [i for i in glob.glob(f\"*.txt\")]\n",
    "df_train_neg = pd.concat([pd.read_table(item, names=[item]) for item in filenames_train_neg])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c3bc9705",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0_3.txt</th>\n",
       "      <th>10000_4.txt</th>\n",
       "      <th>10001_4.txt</th>\n",
       "      <th>10002_1.txt</th>\n",
       "      <th>10003_1.txt</th>\n",
       "      <th>10004_3.txt</th>\n",
       "      <th>10005_3.txt</th>\n",
       "      <th>10006_4.txt</th>\n",
       "      <th>10007_1.txt</th>\n",
       "      <th>10008_2.txt</th>\n",
       "      <th>...</th>\n",
       "      <th>9993_4.txt</th>\n",
       "      <th>9994_2.txt</th>\n",
       "      <th>9995_1.txt</th>\n",
       "      <th>9996_4.txt</th>\n",
       "      <th>9997_2.txt</th>\n",
       "      <th>9998_4.txt</th>\n",
       "      <th>9999_3.txt</th>\n",
       "      <th>999_3.txt</th>\n",
       "      <th>99_1.txt</th>\n",
       "      <th>9_1.txt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Story of a man who has unnatural feelings for ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Airport '77 starts as a brand new luxury 747 p...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>This film lacked something I couldn't put my f...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sorry everyone,,, I know this is supposed to b...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>When I was little my parents took me along to ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 12500 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             0_3.txt  \\\n",
       "0  Story of a man who has unnatural feelings for ...   \n",
       "0                                                NaN   \n",
       "0                                                NaN   \n",
       "0                                                NaN   \n",
       "0                                                NaN   \n",
       "\n",
       "                                         10000_4.txt  \\\n",
       "0                                                NaN   \n",
       "0  Airport '77 starts as a brand new luxury 747 p...   \n",
       "0                                                NaN   \n",
       "0                                                NaN   \n",
       "0                                                NaN   \n",
       "\n",
       "                                         10001_4.txt  \\\n",
       "0                                                NaN   \n",
       "0                                                NaN   \n",
       "0  This film lacked something I couldn't put my f...   \n",
       "0                                                NaN   \n",
       "0                                                NaN   \n",
       "\n",
       "                                         10002_1.txt  \\\n",
       "0                                                NaN   \n",
       "0                                                NaN   \n",
       "0                                                NaN   \n",
       "0  Sorry everyone,,, I know this is supposed to b...   \n",
       "0                                                NaN   \n",
       "\n",
       "                                         10003_1.txt 10004_3.txt 10005_3.txt  \\\n",
       "0                                                NaN         NaN         NaN   \n",
       "0                                                NaN         NaN         NaN   \n",
       "0                                                NaN         NaN         NaN   \n",
       "0                                                NaN         NaN         NaN   \n",
       "0  When I was little my parents took me along to ...         NaN         NaN   \n",
       "\n",
       "  10006_4.txt 10007_1.txt 10008_2.txt  ... 9993_4.txt 9994_2.txt 9995_1.txt  \\\n",
       "0         NaN         NaN         NaN  ...        NaN        NaN        NaN   \n",
       "0         NaN         NaN         NaN  ...        NaN        NaN        NaN   \n",
       "0         NaN         NaN         NaN  ...        NaN        NaN        NaN   \n",
       "0         NaN         NaN         NaN  ...        NaN        NaN        NaN   \n",
       "0         NaN         NaN         NaN  ...        NaN        NaN        NaN   \n",
       "\n",
       "  9996_4.txt 9997_2.txt 9998_4.txt 9999_3.txt 999_3.txt 99_1.txt 9_1.txt  \n",
       "0        NaN        NaN        NaN        NaN       NaN      NaN     NaN  \n",
       "0        NaN        NaN        NaN        NaN       NaN      NaN     NaN  \n",
       "0        NaN        NaN        NaN        NaN       NaN      NaN     NaN  \n",
       "0        NaN        NaN        NaN        NaN       NaN      NaN     NaN  \n",
       "0        NaN        NaN        NaN        NaN       NaN      NaN     NaN  \n",
       "\n",
       "[5 rows x 12500 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_neg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "412685a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_neg.to_csv('df_train_neg.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d4cdca0",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2797697b",
   "metadata": {},
   "source": [
    "## Creating a list of stop words to be applied during vectorization\n",
    "These are words that are either frequently occuring within the english language, within the film industry or simply provide not additional insight. We can begin by importing the *stopwords* module from the **nltk.corpus** library and building upon it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f3bc484",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "179\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords \n",
    "\n",
    "ENGLISH_STOP_WORDS = stopwords.words('english')\n",
    "print(len(ENGLISH_STOP_WORDS))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce3e29f2",
   "metadata": {},
   "source": [
    "With this pre-defined listed of stop-words, we can add onto it stop-words more specific to the film industry, the name of the genres as well as adjectives and adverbs that provide no additional insight other than their inherent meaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3fabff46",
   "metadata": {},
   "outputs": [],
   "source": [
    "ENGLISH_STOP_WORDS.extend(['br', 'bad', 'beautiful', 'best', 'better', 'going', 'great', 'truly', \n",
    "                           'movies', 'movie', 'film', 'films', 'really', 'make', 'don', 'watch', 'seen', \n",
    "                           'actually', 'way', 'screen', 'quite', 'lot', 'drama', 'comedy', \n",
    "                           'action', 'romance', 'crime', 'horror', 'thriller', 'adventure', 'fantasy', 'mystery', \n",
    "                           'sci-fi', 'family', 'biography', 'music', 'war', 'history', 'animation', 'musical', \n",
    "                           'western', 'sport', 'documentary', 'film-noir', 'news', 'adult', 'one', 'like', 'good', \n",
    "                           'even', 'get', 'see', 'would', 'much', 'well', 'also', 'dont', 'could', '310', '410', \n",
    "                           'terrible', 'worst', 'waste', 'awful', 'terrible', 'horrible', 'boring', 'stupid', \n",
    "                           'worse', 'disappointing', 'excellent', 'wonderful', '710', 'favorite', 'perfect', \n",
    "                           'loved', 'amazing', 'enjoyed', '810', '1010', 'awesome'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c8ba3ac",
   "metadata": {},
   "source": [
    "This will be an iterative process; should additional stop-words appear after vectorizing, I can add them to this list and modify my tokenizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "691ba7d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "260\n"
     ]
    }
   ],
   "source": [
    "print(len(ENGLISH_STOP_WORDS))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1df60a4a",
   "metadata": {},
   "source": [
    "We can now save this in .pkl for importing into our modeling notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "86188787",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['stopwords.pkl']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(ENGLISH_STOP_WORDS, 'stopwords.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
